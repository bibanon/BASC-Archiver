#!/usr/bin/env python
# coding: utf-8

# BA 4chan-thread-archiver
#
# Built for the Bibliotheca Anonoma by Antonizoon Overtwater, 2012/04/04
# Rewritten from scratch to use py4chan API wrapper, save in seperate images folder, download plain HTML, modularization, comments, and code cleanup
# Formerly based on https://github.com/socketubs/4chandownloader

#
# Initial release Nov. 5, 2009
# v6 release Jan. 20, 2009
# http://cal.freeshell.org
#
# Refactor, update and Python package
# by Socketubs (http://socketubs.net/)
# 09-08-12
#

import os
import time
import errno

import py4chan
import BA_Archiver.Fourchan

import logging
import sys


"""=== Docopt Arguments and Documentation ==="""

from docopt import docopt

doc = """BA-4chan-thread-archiver. Uses the 4chan API (with the py4chan wrapper) 
to download thread images and/or thumbnails, along with thread HTML, JSON,
and a list of referenced external links.

Usage:
  4chan-thread-archiver <url> [--path=<string>] [--delay=<int>] [--nothumbs] [--thumbsonly] [--enablessl]
  4chan-thread-archiver -h | --help
  4chan-thread-archiver -v | --version

Options:
  --nothumbs          Don't download thumbnails
  --thumbsonly        Download thumbnails, no images
  --enablessl         Download using HTTPS
  --delay=<int>       Delay between thread checks [default: 20]
  -h --help           Show help
  -v --version        Show version
"""



"""=== Constant Variables and Domain Names to Use ==="""

""" Important Message Front Tag """
_TAG = " :: "

""" default folder names for image and thumbnails """
_DEFAULT_FOLDER = "4chan"
_IMAGE_DIR_NAME = "images"
_THUMB_DIR_NAME = "thumbs"
_CSS_DIR_NAME = "css"



def timestamp():
    """ 
        `Timestamp` <http://www.interfaceware.com/manual/timestamps_with_milliseconds.html>_
    """
    
    now = time.time()
    localtime = time.localtime(now)
    return time.strftime('%Y-%m-%d %H:%M:%S', localtime)

def check_url(url):
  """
      Make sure that the given URL is a valid 4chan thread URL.
      Originates from The Chandler by Dhole
  """
  url_parsed = re.findall("http(?:s)?://(?:boards.)?.*/*/res/[0-9]*(?:.php|.html)?", url)
  if len(url_parsed) < 1:
    return ""
  else:
    return url_parsed[0]



"""=== Main Function ==="""

def main(args):
    """
       Check 4chan API for new content, and recursively dump thread
    """
    # Setup logging to display to stderr
    formatter = logging.Formatter('[%(levelname)s] %(message)s')
    handler = logging.StreamHandler(stream=sys.stdout)
    handler.setFormatter(formatter)
    handler.setLevel(logging.INFO)

    # Stop the script if the given URL is malformed
    if (check_url(args.get('<url>')) == ""):
      print(_TAG + "The URL is invalid, or it isn't a 4chan thread URL.")
      raise SystemExit(0)

    # Copy data from docopt arguments
    thread = args.get('<url>').split('/')[5]
    board  = args.get('<url>').split('/')[3]
    path   = args.get('--path')
    nothumbs = args.get('--nothumbs', False)
    thumbsonly = args.get('--thumbsonly', False)
    enablessl = args.get('--enablessl', False)
    delay  = args.get('--delay')


    # Set a default path if none is given
    if (path == None):
      path = os.path.join(os.getcwd() + os.path.sep + _DEFAULT_FOLDER)
      
    # Set destination directory
    dst_dir = os.path.join(path, board, thread)

    # Initialize Archiver object
    curr_archiver = BA_Archiver.Fourchan.Archiver(board, thread, dst_dir, https=enablessl)


    # header
    print(_TAG + 'Board : 4chan /%s/' % board)
    print(_TAG + 'Thread: %s' % thread)
    print(_TAG + 'Folder: %s' % dst_dir)


    # Using try/except loop to handle Ctrl-C
    try:
      # Switch to check for first run
      first_iteration = True
      
      while 1:
        # don't run this code the first time
        if (first_iteration == False):
          
          # Wait to execute code again
          print("\n" + _TAG + "Waiting %s seconds before retrying (Type Ctrl-C to stop)" % delay)
          time.sleep(int(delay))
          
          if curr_thread.is_404:
            # Stop when thread gets 404'ed
            print(_TAG + "%s - [Thread 404'ed or Connection Lost]" % timestamp())
            print(" :: Dump complete. To resume dumping the same thread,\nrun this script again.")
            raise SystemExit(0)
            
          
          # Update thread and check if new replies have appeared
          new_replies = curr_thread.update()
          if (new_replies == 0):
            print(_TAG + "%s - [No new posts.]" % timestamp())
            continue
          
          else:
            print(_TAG + "%s - [%s new post(s) found!]" % (timestamp(), new_replies))
            
          # If all tests are OK, dump thread again
          curr_archiver.dump(nothumbs, thumbsonly)
              
        else:
          # dump thread for the first time
          print(_TAG + "Dumping the thread...")
          curr_archiver.dump(nothumbs, thumbsonly)
          
          # first iteration is complete
          first_iteration = False
          
    except KeyboardInterrupt:
      """
          Stop try/except loop when [Ctrl-C] is pressed
      """
      print("\n")
      print(" :: Dump complete. To resume dumping the same thread,\nrun this script again.")
      raise SystemExit(0)



"""
    Use docopt to get arguments, and run main function
"""
if __name__ == '__main__':
  args = docopt(doc, version=0.3)
  main(args)
